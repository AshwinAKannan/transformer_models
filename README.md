# transformer_models


Useful resources

Videos

Transformers:

https://www.youtube.com/watch?v=S27pHKBEp30&ab_channel=SeattleAppliedDeepLearning
https://www.youtube.com/watch?v=4Bdc55j80l8&ab_channel=TheA.I.Hacker-MichaelPhi

BERT:
https://www.youtube.com/playlist?list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6

Blogs

http://jalammar.github.io/illustrated-transformer/
https://medium.com/@hirotoschwert/an-unofficial-colab-walkthrough-of-vision-transformer-8bcd592ba26a
https://towardsdatascience.com/transformers-141e32e69591

Question in mind: how does the decoder get trained?
https://ai.stackexchange.com/questions/12490/can-the-decoder-in-a-transformer-model-be-parallelized-like-the-encoder

- decoder is still trained one step at a time, with each time step getting input from previous time step




